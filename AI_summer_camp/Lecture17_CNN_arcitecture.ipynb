{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture17 CNN arcitecture.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF1vMa8KzM1q",
        "colab_type": "text"
      },
      "source": [
        "##0.개요\n",
        "https://ratsgo.github.io/deep%20learning/2017/10/09/CNNs/\n",
        "* AlexNet : 최초의 의미있는 성능의 CNN, 드랍아웃 기법의 표준화\n",
        "* GoogLeNet : 1x1 conv filter의 차원감소\n",
        "* ResNet : 기존의 층이 깊어질수록 역전파되는 그래디언트가 중간에 죽어 학습이 잘 되지 않는 문제(gradient vanishing)이 발생 -> residual block(**for skip connection**,forget gate를 도입해 이전 스텝의 그래디언트 정보를 좀더 잘 흐르게 만드려는 LSTM과 본질적으로 유사)\n",
        "![residual block](https://i.imgur.com/fse3Ntq.png)\n",
        "![unraveled view](https://i.imgur.com/CjLtXb0.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyA3IN0N-T5U",
        "colab_type": "text"
      },
      "source": [
        "##1.AlexNet\n",
        "* 우수한 정확도\n",
        "* 2개의 GPU를 사용한 구조(그 당시 3GB였기 때문)\n",
        "* 5개의 Conv 레이어, 3개의 FC 레이어\n",
        "* 3차원 구조의 convolution layer\n",
        " * RGB -> depth=3\n",
        "* zero-padding을 통해 얻은 이미지(227,227,3)->컨볼루션 커널(11,11,3,96) 통과 -> 출력 이미지 (55,55,96) ->풀링하여 927,27,96)->conv kernel(5,5,96,256) 통과->27,27,256 이미지 ->conv()\n",
        "\n",
        "* Lateral inhibition 현상에서 모델링하여 local response normalization->generalization 관점에서 더 좋은 정확도를 얻는것이 가능\n",
        "* Data augment, relu, dropout\n",
        "* 파라미터의 연산량을 줄이는 것이 모델 설계의 핵심\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oPGHpEAkQXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def AlexNet():\n",
        "    \n",
        "    model = keras.Sequential()\n",
        "    \n",
        "    model.add(keras.layers.Conv2D(filters=96, kernel_size= 11, strides=4, padding='SAME', activation = tf.nn.relu, input_shape=(224,224,3)))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size= 2, strides= 2, padding= 'SAME'))\n",
        "    \n",
        "    model.add(keras.layers.Conv2D(filters=256, kernel_size=5, strides=1, padding='SAME', activation = tf.nn.relu))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size= 2, strides= 2, padding='SAME'))\n",
        "\n",
        "    model.add(keras.layers.Conv2D(filters=384, kernel_size= 3, strides=1, padding='SAME', activation = tf.nn.relu))\n",
        "    model.add(keras.layers.Conv2D(filters=384, kernel_size= 3, strides= 1, padding='SAME', activation = tf.nn.relu))\n",
        "    model.add(keras.layers.Conv2D(filters=256, kernel_size= 3, strides= 3, padding='SAME', activation = tf.nn.relu))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size= 2, strides= 2, padding='SAME'))\n",
        "\n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dense(4096, input_shape=(224*224*3,), activation = tf.nn.relu))\n",
        "    model.add(keras.layers.Dropout(0.4))\n",
        "    \n",
        "    model.add(keras.layers.Dense(4096, activation = tf.nn.relu))\n",
        "    model.add(keras.layers.Dropout(0.4))\n",
        "    \n",
        "    model.add(keras.layers.Dense(1000, activation = tf.nn.softmax))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O2fXIn2SL9T",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "##2.VGG16\n",
        "* 신경망의 깊이가 깊어짐\n",
        " * 장점 : 더 복잡한 문제의 해결\n",
        "  * 파라미터와 연산량의 증가, 그리고 overfitting\n",
        "\n",
        "* 파라미터의 숫자를 줄이는 방법\n",
        " * 5 x 5 conv 하나보다 3 x 3 두개가 낫다. 즉 여러개의 작은 conv filter(3 by 3 이하만) 쓰는 것이 적은 파라미터와 연산량으로 가능하다.\n",
        " * 3 x 3 2개 = 5 x 5 1개\n",
        " * 3 x 3 3개 = 7 x 7 1개\n",
        "\n",
        "* Vanishing gradient 문제를 해결하기 위해 11-layer의 학습 결과를 더 깊은 layer의 파라미터 초기화에 사용\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei-P5h3Uke4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def VGG16():\n",
        "    model = keras.Sequential()\n",
        "    #3 x 3 convolution만을 사용\n",
        "    \n",
        "    model.add(keras.layers.Conv2D(filters = 64, kernel_size = 3, activation= 'relu', padding= 'SAME', input_shape = (224, 224, 3)))\n",
        "    model.add(keras.layers.Conv2D(filters = 64, kernel_size = 3, activation= 'relu', padding= 'SAME'))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "    \n",
        "    \n",
        "    model.add(keras.layers.Conv2D(filters = 128, kernel_size = 3, activation= 'relu', padding= 'SAME'))\n",
        "    model.add(keras.layers.Conv2D(filters = 128, kernel_size = 3, activation= 'relu', padding= 'SAME'))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "    \n",
        "    \n",
        "    model.add(keras.layers.Conv2D(filters = 256, kernel_size = 3, activation= 'relu', padding= 'SAME'))\n",
        "    model.add(keras.layers.Conv2D(filters = 256, kernel_size = 3, activation= 'relu', padding= 'SAME'))\n",
        "    model.add(keras.layers.Conv2D(filters = 256, kernel_size = 3, activation= 'relu', padding= 'SAME'))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "    \n",
        "    \n",
        "    model.add(keras.layers.Conv2D(filters = 512, kernel_size = 3, activation= 'relu', padding= 'SAME'))\n",
        "    model.add(keras.layers.Conv2D(filters = 512, kernel_size = 3, activation= 'relu', padding= 'SAME'))\n",
        "    model.add(keras.layers.Conv2D(filters = 512, kernel_size = 3, activation= 'relu', padding= 'SAME'))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "    \n",
        "    \n",
        "    model.add(keras.layers.Conv2D(filters = 512, kernel_size = 3, activation= 'relu', padding= 'SAME'))\n",
        "    model.add(keras.layers.Conv2D(filters = 512, kernel_size = 3, activation= 'relu', padding= 'SAME'))\n",
        "    model.add(keras.layers.Conv2D(filters = 512, kernel_size = 3, activation= 'relu', padding= 'SAME'))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2))\n",
        "    \n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dense(4096, activation= tf.nn.relu))\n",
        "    model.add(keras.layers.Dense(4096, activation= tf.nn.relu))\n",
        "    model.add(keras.layers.Dense(1000, activation= tf.nn.softmax))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtzxGgzDSOAQ",
        "colab_type": "text"
      },
      "source": [
        "##3.GoogLeNet\n",
        "* 1 x 1 conv : 차원을 줄이는 방법. 비슷한 성질을 갖는 것들 묶음, 피쳐맵과 연산량을 줄이는데 특화\n",
        "* Inception module -> 1,3,5 square의 conv를 각각 수행\n",
        "* 보조분류기 사용\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTAh8N7KkxSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GoogLeNet():\n",
        "    def inception_block(input_layer, filter1, filter2, filter3, reduce1, reduce2, pool_proj):\n",
        "    # TODO : 1 x 1 Convolution 수행\n",
        "    conv1x1 = Conv2D(filter1, kernel_size=(1,1), padding='same', activation='relu')(input_layer)\n",
        "    \n",
        "    # TODO : 1 x 1 Convolution 후 3 x 3 Convolution 수행\n",
        "    conv3x3_reduce = Conv2D(reduce1, kernel_size=(1,1), padding='same', activation='relu')(input_layer)\n",
        "    conv3x3 = Conv2D(filter2, kernel_size=(3,3), padding='same', activation='relu')(conv3x3_reduce)\n",
        "    \n",
        "    # TODO : 1 x 1 Convolution 후 5 x 5 Convolution 수행\n",
        "    conv5x5_reduce = Conv2D(reduce2, kernel_size=(1,1), padding='same', activation='relu')(input_layer)\n",
        "    conv5x5 = Conv2D(filter3, kernel_size=(5,5), padding='same', activation='relu')(conv5x5_reduce)\n",
        "    \n",
        "    # TODO : Max pooling 후 1 x 1 Convolution 수행\n",
        "    pooling = MaxPooling2D((3,3), strides=(1,1), padding='same')(input_layer)\n",
        "    pool_proj = Conv2D(pool_proj, kernel_size=(1,1), padding='same', activation='relu')(pooling)\n",
        "    \n",
        "    # TODO : 개별적으로 연산이 끝난 후 Feature map을 합쳐줍니다.\n",
        "    output_layer = concatenate([conv1x1,conv3x3,conv5x5,pool_proj])\n",
        "    \n",
        "    return output_layer\n",
        "\n",
        "    # Gradient Vanishing Problem을 막기 위한 Auxiliary_classifier\n",
        "    def Auxiliary_classifier(input_layer, filter1, dense1, dense2, drop_prob):\n",
        "        loss_ave_pool = AveragePooling2D(pool_size= 5, strides= 3)(input_layer)\n",
        "        loss_conv = Conv2D(filter1, kernel_size = (1,1), padding='same', activation='relu', kernel_regularizer=l2(0.0002))(loss_ave_pool)\n",
        "        loss_flat = Flatten()(loss_conv)\n",
        "        loss_fc = Dense(dense1, kernel_regularizer=l2(0.0002), activation='relu')(loss_flat)\n",
        "        loss_drop_fc = Dropout(drop_prob)(loss_fc)\n",
        "        # 총 1000개의 클래스를 분류하기 때문에 마지막 node의 개수는 1000개입니다.\n",
        "        loss_classifier = Dense(dense2, kernel_regularizer=l2(0.0002), activation='softmax')(loss_drop_fc)\n",
        "\n",
        "        return loss_classifier\n",
        "\n",
        "    # 입력 선언\n",
        "    def model():\n",
        "        shape = (224,224,3)\n",
        "        inputs = Input(shape)\n",
        "\n",
        "        # 초기 입력의 크기를 줄이기 위한 Conv Layer\n",
        "        conv_7x7 = Conv2D(64, kernel_size=(7,7), strides= (2,2), padding='same', activation='relu', kernel_regularizer=l2(0.0002))(inputs)\n",
        "        max_pool1 = MaxPooling2D((3,3), strides=(2,2), padding='same')(conv_7x7)\n",
        "        conv_3x3 = Conv2D(192, (3,3),strides=(1,1), padding='same', activation='relu', kernel_regularizer=l2(0.0002))(max_pool1)\n",
        "        max_pool2 = MaxPooling2D((3,3), strides=(2,2), padding='same')(conv_3x3)\n",
        "\n",
        "        inception_reduce_1 = inception_block(max_pool2, 64, 128, 32, 96, 16, 32)\n",
        "        inception_reduce_2 = inception_block(inception_reduce_1, 128, 192, 96, 128, 32, 64)\n",
        "\n",
        "        # Max Pooling Layer로 Feature map의 크기 감소.\n",
        "        max_pool3 = MaxPooling2D((3,3), strides=(2,2), padding='same')(inception_reduce_2)\n",
        "\n",
        "        .\n",
        "        inception_reduce_3 = inception_block(max_pool3, 192, 208, 48, 96, 16, 64)\n",
        "        inception_reduce_4 = inception_block(inception_reduce_3, 160, 224, 64, 112, 24, 64)\n",
        "\n",
        "        # 첫 번째 Auxiliary Classifier를 4번째 Inception 모듈 뒤에 쌓는다.\n",
        "        loss_classifier1 = Auxiliary_classifier(inception_reduce_4, 128, 1024, 1000, 0.7)\n",
        "\n",
        "        inception_reduce_5 = inception_block(inception_reduce_4, 128, 256, 64, 128, 24, 64)\n",
        "        inception_reduce_6 = inception_block(inception_reduce_5, 112, 288, 64, 144, 32, 64)\n",
        "        inception_reduce_7 = inception_block(inception_reduce_6, 256, 320, 128, 160, 32, 128)\n",
        "\n",
        "        max_pool4 = MaxPooling2D((3,3), strides=(2,2), padding='same')(inception_reduce_7)\n",
        "\n",
        "        # 두 번째 Auxiliary Classifier를 7번째 Inception 모듈 뒤에 쌓는다.\n",
        "        loss_classifier2 = Auxiliary_classifier(inception_reduce_7, 128, 1024, 1000, 0.7)\n",
        "\n",
        "        inception_reduce_8 = inception_block(max_pool4, 256, 320, 128, 160, 32, 128)\n",
        "        inception_reduce_9 = inception_block(inception_reduce_8, 384, 384, 128, 192, 48, 128)\n",
        "\n",
        "        # Average Pooling Layer로 학습된 Feature들의 평균을 구함\n",
        "        avg_pool = AveragePooling2D(pool_size= 7, strides= 1)(inception_reduce_9)\n",
        "        drop_out_layer = Dropout(0.4)(avg_pool)\n",
        "\n",
        "        loss_classifier3 = Dense(1000)(drop_out_layer)\n",
        "\n",
        "        \n",
        "        model = Model(inputs = inputs, outputs = [loss_classifier1,loss_classifier2,loss_classifier3])\n",
        "        model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnd6Yp7gC9E5",
        "colab_type": "text"
      },
      "source": [
        "##4.ResNet\n",
        "* 깊은 망 -> vanishing gradient\n",
        "* 입력과 출려의 차이값(F(x)=H(x)-x)를 찾는것. F(x)=0 최적의 경우 학습의 목표가 정해진 상태에서 학습\n",
        "* Bottleneck block : 두 종류의 residual block 사용, deep한 신경망 만들기 위해 3 layer 모델 사용\n",
        "* 5종류, 망 깊이와 정확도 비례\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XxcvmrAEfoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def identity_block(input_tensor, kernel_size, filters):\n",
        "    \n",
        "    filters1, filters2, filters3 = filters\n",
        "    \n",
        "    x = Conv2D(filters1, (1, 1))(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters2, kernel_size, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters3, (1, 1))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    # 입력(x) : input_tensor와 F(x) : x를 더해줍니다.\n",
        "    # TODO : add()와 Activation() 메서드를 사용해서 relu(F(x) + x) 의 형태로 만들어보세요. \n",
        "    x = add([input_tensor,x])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def residual_block(input_tensor, kernel_size, filters, strides=(2, 2)):\n",
        "    filters1 , filters2 , filters3 = filters\n",
        "    \n",
        "    # 입력 Feature Map의 Size를 1/2로 감소, Feature map의 Dimension을 2배로 증가\n",
        "    x = Conv2D(filters1, (1, 1), strides=strides)(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters2, kernel_size, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters3, (1, 1))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    shortcut = Conv2D(filters3 ,(1,1),strides=strides)(x)\n",
        "    shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    x = add([x,shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "\n",
        "def ResNet50():\n",
        "    \n",
        "    shape = (224,224,3)\n",
        "    inputs = Input(shape)\n",
        "    \n",
        "    # 입력 영상의 크기를 줄이기 위한 Conv & Max-pooling\n",
        "    x = ZeroPadding2D((3, 3))(inputs)\n",
        "    x = Conv2D(64, (7, 7), strides=(2, 2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "    \n",
        "    # 첫 번째 Residual Block (입력 영상 Size 2배 축소 / Dimension 2배 증가)\n",
        "    x = residual_block(x, 3, [64, 64, 256], strides=(1, 1))\n",
        "    x = identity_block(x, 3, [64, 64, 256])\n",
        "    x = identity_block(x, 3, [64, 64, 256])\n",
        "    \n",
        "    \n",
        "    # 두 번째 Residual Block (입력 영상 Size 2배 축소 / Dimension 2배 증가)\n",
        "    x = residual_block(x, 3, [128, 128, 512])\n",
        "    x = identity_block(x, 3, [128, 128, 512])\n",
        "    x = identity_block(x, 3, [128, 128, 512])\n",
        "    x = identity_block(x, 3, [128, 128, 512])\n",
        "    \n",
        "    # 세 번째 Residual Block (입력 영상 Size 2배 축소 / Dimension 2배 증가)\n",
        "    x = residual_block(x, 3, [256, 256, 1024])\n",
        "    x = identity_block(x, 3, [256, 256, 1024])\n",
        "    x = identity_block(x, 3, [256, 256, 1024])\n",
        "    x = identity_block(x, 3, [256, 256, 1024])\n",
        "    x = identity_block(x, 3, [256, 256, 1024])\n",
        "    x = identity_block(x, 3, [256, 256, 1024])\n",
        "    \n",
        "    # 네 번째 Residual Block (입력 영상 Size 2배 축소 / Dimension 2배 증가)\n",
        "    x = residual_block(x, 3, [512, 512, 2048])\n",
        "    x = identity_block(x, 3, [512, 512, 2048])\n",
        "    x = identity_block(x, 3, [512, 512, 2048])\n",
        "\n",
        "    # 마지막단에서 FC layer를 쓰지 않고 단순히 Averaging\n",
        "    x = AveragePooling2D((7, 7))(x)\n",
        "    x = Flatten()(x)\n",
        "    \n",
        "    x = Dense(1000, activation='softmax')(x)\n",
        "    \n",
        "    model = Model(inputs, x)\n",
        "    return model\n",
        "\n",
        "model = ResNet50()\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}